{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4277/CS5477 Lab 1: Fun with Homographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%aimport lab1\n",
    "from lab1 import *\n",
    "\n",
    "np.set_printoptions(precision=6)  # Print less digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this assignment, you will get to implement a panorama stitching algorithm. As discussed in the lectures, images taken using a purely-rotating camera are related by a homography, which can be estimated by at least four point correspondences. You will first implement a homography estimation algorithm, then add a RANSAC scheme to reject outliers. You will also implement a image warping function and use it to stitch together multiple images into a single coherent panorama.\n",
    "\n",
    "This assignment is worth **15%** of the final grade.\n",
    "\n",
    "References:\n",
    "* Lecture 3\n",
    "\n",
    "Optional references:\n",
    "* HZ Book, Sections 4.1, 4.7, 4.8\n",
    "\n",
    "### Instructions\n",
    "This workbook provides the instructions for the assignment, and facilitates the running of your code and visualization of the results. For each part of the assignment, you are required to **complete the implementations of certain functions in the accompanying python file** (`lab1.py`).\n",
    "\n",
    "To facilitate implementation and grading, all your work is to be done in that file, and **you only have to submit the .py file**.\n",
    "\n",
    "Please note the following:\n",
    "1. Fill in your name, email, and student number at the top of the python file.\n",
    "2. The parts you need to implement are clearly marked with the following:\n",
    "\n",
    "    ```\n",
    "    \"\"\" YOUR CODE STARTS HERE \"\"\"\n",
    "\n",
    "    \"\"\" YOUR CODE ENDS HERE \"\"\"\n",
    "    ```\n",
    "    \n",
    "    , and you should write your code in between the above two lines.\n",
    "3. Note that for each part, there may be certain functions that are prohibited to be used. It is important **NOT to use those prohibited functions** (or other functions with similar functionality). If you are unsure whether a particular function is allowed, feel free to ask any of the TAs.\n",
    "\n",
    "\n",
    "### Submission Instructions\n",
    "Upload your completed `lab1.py` onto the relevant work bin in Luminus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Homography Estimation from Point Correspondences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will implement the *Normalized Direct Linear Transformation (DLT)* algorithm for homography estimation. This is a linear algorithm for determining the homography transformation $\\mathbf{H}$ given at least four 2D to 2D point correspondences $\\mathbf{x}_i \\leftrightarrow \\mathbf{x}'_i$ (in homogeneous coordinates). The goal is to compute the $3 \\times 3$ homography matrix $\\mathbf{H}$ such that $\\mathbf{Hx}_i = \\mathbf{x}'_i$ for each $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(a) Transformation using provided homography matrix\n",
    "To ensure you understand the homography transformation, first implement the function that transform 2D points using a provided homography matrix.\n",
    "\n",
    "**Implement the following function(s): `transform_homography()`**\n",
    "* <u>Prohibited Functions</u>: `cv2.perspectiveTransform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_pts = np.array([[0.0, 0.0], [0.5, 0.0], [1.0, 0.0], [1.0, 0.5],\n",
    "                      [1.0, 1.0], [0.5, 1.0], [0.0, 1.0], [0.0, 0.5]])\n",
    "\n",
    "cases = ['translation', 'rigid', 'affine', 'homography']\n",
    "h = {}\n",
    "h['translation'] = np.array([[1.0, 0.0, 1.0],\n",
    "                             [0.0, 1.0, 0.5],\n",
    "                             [0.0, 0.0, 1.0]])\n",
    "h['rigid'] = np.array([[0.8660254, -0.5, 0.5],\n",
    "                       [0.5, 0.8660254, 0.1],\n",
    "                       [0.0, 0.0, 1.0]])\n",
    "h['affine'] = np.array([[1.0, 0.5, 0.0],\n",
    "                        [0.0, 1.5, 0.0],\n",
    "                        [0.0, 0.0, 1.0]])\n",
    "h['homography'] = np.array([[1.0, 0.2, 0.0],\n",
    "                       [0.0, 1.5, 0.0],\n",
    "                       [0.0, 0.5, 1.0]])\n",
    "\n",
    "output_pts = {}\n",
    "for c in cases:\n",
    "    output_pts[c] = transform_homography(input_pts, h[c])\n",
    "\n",
    "# Print output points and plot\n",
    "for c in cases:\n",
    "    print('Points after ({})\\n'.format(c), output_pts[c].transpose())\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ax.axis('equal')\n",
    "    ax.set(xlim=(-1.0, 3.0), ylim=(-1.0, 3.0))\n",
    "    plt.title('Before {}'.format(c))\n",
    "    plt.plot(input_pts[:, 0], input_pts[:, 1], '*')\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    ax.axis('equal')\n",
    "    ax.set(xlim=(-1.0, 3.0), ylim=(-1.0, 3.0))\n",
    "    plt.title('After {}'.format(c))\n",
    "    plt.plot(output_pts[c][:, 0], output_pts[c][:, 1], '*');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following if the function is implemented correctly:\n",
    "```\n",
    "Points after (translation)\n",
    " [[1.  1.5 2.  2.  2.  1.5 1.  1. ]\n",
    " [0.5 0.5 0.5 1.  1.5 1.5 1.5 1. ]]\n",
    "Points after (rigid)\n",
    " [[0.5      0.933013 1.366025 1.116025 0.866025 0.433013 0.       0.25    ]\n",
    " [0.1      0.35     0.6      1.033013 1.466025 1.216025 0.966025 0.533013]]\n",
    "Points after (affine)\n",
    " [[0.   0.5  1.   1.25 1.5  1.   0.5  0.25]\n",
    " [0.   0.   0.   0.75 1.5  1.5  1.5  0.75]]\n",
    "Points after (homography)\n",
    " [[0.       0.5      1.       0.88     0.8      0.466667 0.133333 0.08    ]\n",
    " [0.       0.       0.       0.6      1.       1.       1.       0.6     ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(b) Compute Homography Matrix\n",
    "\n",
    "Now, implement the function to compute the homography matrix given pairs of correspondences using the *normalized* DLT algorithm.\n",
    "\n",
    "**Implement the following function(s): `compute_homography()`**\n",
    "* <u>Prohibited Functions</u>:\n",
    "  `cv2.findHomography()`, `cv2.getPerspectiveTransform()`, `np.linalg.solve()`, `np.linalg.lstsq()`\n",
    "* <u>You may use the following functions</u>:\n",
    "  `np.linalg.svd()`\n",
    "\n",
    "Remember to use normalization, which will increase the robustness of the estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test case with exactly 4 points\n",
    "src1 = np.array([[0.0, 0.0], [331.0, 0.0], [331.0, 474.0], [0.0, 474.0]])\n",
    "dst1 = np.array([[182.0, 94.0], [482.0, 48.0], [598.0, 466.0], [146.0, 533.0]])\n",
    "homo1 = compute_homography(src1, dst1)\n",
    "\n",
    "# Test case with more than 4 points\n",
    "src2 = np.array([[434.375, 93.625], [429.625, 190.625], \n",
    "                 [533.625, 301.875], [452.375, 460.625], \n",
    "                 [558.375, 188.625], [342.444, 362.596], \n",
    "                 [345.625, 41.875], [341.625, 146.125]])\n",
    "dst2 = np.array([[204.780, 92.367], [201.875, 190.625], \n",
    "                 [297.125, 296.875], [224.446, 456.556],\n",
    "                 [318.407, 192.155], [107.625, 371.375],\n",
    "                 [109.875, 26.624], [106.625, 138.125]])\n",
    "homo2 = compute_homography(src2, dst2)\n",
    "\n",
    "print('homo1:\\n', homo1, '\\n')\n",
    "print('homo2:\\n', homo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should obtain approximately the following (or some scale of it) if your function is implemented correctly:\n",
    "\n",
    "```\n",
    "homo1:\n",
    " [[ 9.012217e-01 -1.792522e-01  1.820000e+02]\n",
    " [-1.394830e-01  5.490343e-01  9.400000e+01]\n",
    " [-1.062811e-05 -7.075535e-04  1.000000e+00]]\n",
    " \n",
    "homo2:\n",
    " [[ 1.738142e+00  9.494425e-03 -4.466937e+02]\n",
    " [ 2.745643e-01  1.514698e+00 -1.213769e+02]\n",
    " [ 1.160079e-03  2.069049e-05  1.000000e+00]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Image Warping using Homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will implement the image warping function. Given two images $I_{src}, I_{dst}$ and the homography matrix $\\mathbf{H}$ which relates the coordinates in the two images:\n",
    "$$\n",
    "\\mathbf{x}_{dst} = \\mathbf{H}\\mathbf{x}_{src}\n",
    "$$,\n",
    "where $\\mathbf{x}_{src}$ and $\\mathbf{x}_{dst}$ are pixel coordinates of $I_{src}$ and $I_{dst}$ respectively, the objective is to warp $I_{src}$ onto $I_{dst}$.\n",
    "\n",
    "The obvious way of doing this is forward-interpolation, where for every pixel in $I_{src}$, you compute where it should be in $I_{dst}$ and copy the pixel value over. However this will result in holes in the image (why?).\n",
    "\n",
    "The better way is to do it in the reverse direction (i.e. backward interpolation), where we compute the corresponding coordinate in $I_{src}$ for every pixel in $I_{dst}$. First create a $H_{dst}W_{dst}\\times2$ matrix containing the coordinates of all the pixels in $I_{dst}$, i.e,\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & \\dots & W_{dst}-1 & W_{dst}-1 \\\\\n",
    "0 & 1 & 2 & \\dots & H_{dst}-2 & H_{dst}-1\n",
    "\\end{bmatrix}^T,\n",
    "$$\n",
    "where $W_{dst}$ and $H_{dst}$ are the width and height of $I_{dst}$. Then use your `transform_homography()` function to compute the corresponding coordinates in $I_{src}$. Lastly, for every pixel in the destination image, fill its value with the corresponding pixel in the source image;  you can use interpolation methods to handle non-integer soure pixel coordinates.\n",
    "\n",
    "**Implement the following function(s): `warp_image()`**\n",
    "\n",
    "* <u>Prohibited Functions</u>:\n",
    "  `cv2.warpPerspective()`\n",
    "* <u>You may use the following functions</u>:\n",
    "  `cv2.remap(), np.meshgrid()`\n",
    "  \n",
    "If you use `cv2.remap`, you might find the `borderMode` value of `cv2.BORDER_TRANSPARENT` useful. Also consider using bilinear interpolation in `cv2.remap`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now use our functions so far to replace the book cover with another image. If all above functions are implemented correctly, you should see the book cover being replaced by another image when you run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = load_image('data/hzbook_2.jpg')\n",
    "original = load_image('data/hzbook_1.jpg')\n",
    "# homo is the homography matrix that maps points in template to original\n",
    "homo = np.array([[ 9.01221661e-01, -1.79252179e-01, 1.82000000e+02],\n",
    "                 [-1.39482959e-01,  5.49034320e-01, 9.40000000e+01],\n",
    "                 [-1.06281109e-05, -7.07553504e-04, 1.00000000e+00]])\n",
    "overlaid = warp_image(template, original, homo)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(template)\n",
    "plt.title('Template')\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(original)\n",
    "plt.title('Original image')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(overlaid)\n",
    "plt.title('Modified image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Robust Homography Estimation using RANSAC\n",
    "In this part, we upgrade our homography estimation algorithm to be robust even in the presence of outliers. Consider the following image stitching example containing 10 provided correspondences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = load_image('data/pano_2.jpg')\n",
    "im2 = load_image('data/pano_3.jpg')\n",
    "\n",
    "im1_points = np.array([[434.375, 93.625], [429.625, 190.625], \n",
    "                       [533.625, 301.875], [452.375, 460.625], \n",
    "                       [558.375, 188.625], [342.444, 362.596], \n",
    "                       [345.625, 41.875], [341.625, 146.125], \n",
    "                       [424.375, 385.375], [602.875, 183.125]])  # last row is outliers\n",
    "\n",
    "im2_points = np.array([[204.780, 92.367], [201.875, 190.625], \n",
    "                       [297.125, 296.875], [224.446, 456.556],\n",
    "                       [318.407, 192.155], [107.625, 371.375],\n",
    "                       [109.875, 26.624], [106.625, 138.125],\n",
    "                       [514.526, 142.354], [348.375, 304.375]])  # last row is outliers\n",
    "\n",
    "vis = draw_matches(im1, im2, im1_points, im2_points)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(vis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that 2 of the 10 correspondences are wrong. Using just the correct correspondences yields the correct result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "im1_points_inliers = im1_points[:-2, :]  # exclude the last 2 wrong correspondences\n",
    "im2_points_inliers = im2_points[:-2, :]\n",
    "homo = compute_homography(im1_points_inliers, im2_points_inliers)\n",
    "\n",
    "stitched = warp_images_all([im1, im2], [homo, np.eye(3)])\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(stitched)\n",
    "\n",
    "print('Computed homography matrix:\\n', homo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we include the two outliers, notice that the alignment fails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "homo = compute_homography(im1_points, im2_points)\n",
    "\n",
    "stitched = warp_images_all([im2, im1], [np.eye(3), homo])\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(stitched);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The de-facto algorithm to solve this is RANdom SAmple Consensus (RANSAC). Your task is now to implement the robust homography computation which can handle outliers. RANSAC requires a error distance function to compute which correspondences are outliers. First, implement the symmetric transfer error distance measure as described in the lectures:\n",
    "\n",
    "$$\n",
    "d(x,x';H) = \\left\\lVert x - H^{-1}x' \\right\\rVert^2 + \\left\\lVert x' - Hx \\right\\rVert^2.\n",
    "$$\n",
    "\n",
    "**Implement the following function(s): compute_homography_error()**\n",
    "* <u>Prohibited Functions</u>:\n",
    "  `cv2.findHomography()`\n",
    "* <u>You may use the following functions</u>:\n",
    "  `np.linalg.inv()`, and `transform_homography()` from the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = np.array([[0.0, 0.0], [1.0, 0.0], [2.0, 1.0]])\n",
    "dst = np.array([[1.0, 2.0], [1.5, 2.5], [2.5, 3]])\n",
    "H = np.array([[0.5, 0.0, 1.0],\n",
    "              [0.0, 0.5, 2.0],\n",
    "              [0.0, 0.0, 1.0]])\n",
    "\n",
    "print('Error:', compute_homography_error(src, dst, H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If implemented correctly, the previous code should print:\n",
    "\n",
    "```\n",
    "Error: [0.   1.25 2.5 ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the RANSAC procedure covered in the lectures, using the error distance measure you just implemented:\n",
    "\n",
    "*Be sure to re-estimate the homography transformation using all the inliers at the end of the RANSAC procedure.*\n",
    "\n",
    "**Implement the following function(s): `compute_homography_ransac()`**\n",
    "\n",
    "* <u>Prohibited Functions</u>:\n",
    "  `cv2.findHomography()`\n",
    "* <u>You may use the following functions</u>:\n",
    "  `compute_homography(), compute_homography_error()` from the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo, mask = compute_homography_ransac(im1_points, im2_points)\n",
    "\n",
    "stitched = warp_images_all([im1, im2], [homo, np.eye(3)])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(stitched)\n",
    "\n",
    "vis = draw_matches(im1, im2, im1_points, im2_points, inlier_mask=mask)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(vis)\n",
    "\n",
    "print('Computed homography matrix:\\n', homo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented the above correctly, the above images should be aligned correctly. The RANSAC algorithm detects outliers (drawn in red) and excludes them from the homography computation. The computed homography matrix should be the same as the previous sections:\n",
    "```\n",
    " [[ 1.738142e+00  9.494425e-03 -4.466937e+02]\n",
    " [ 2.745643e-01  1.514698e+00 -1.213769e+02]\n",
    " [ 1.160079e-03  2.069049e-05  1.000000e+00]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we now can perform automatic alignment of the image pair. Recall in the lectures that we can detect keypoints and match them between the two images. The matches generally will contain outliers but your robust homography computation can handle those and still output the correct homography.\n",
    "\n",
    "Let's see how our algorithm performs in such a scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us use OpenCV's feature detection, extraction and matching pipeline to establish potential correspondences in the two images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initiate ORB detector. Detect keypoints and extracts descriptors with ORB\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY), None)\n",
    "kp2, des2 = orb.detectAndCompute(cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY), None)\n",
    "\n",
    "# Matches the descriptors via brute force matching\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1,des2)\n",
    "im1_points_orb, im2_points_orb = matches2pairs(matches, kp1, kp2)\n",
    "\n",
    "vis = draw_matches(im1, im2, im1_points_orb, im2_points_orb)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(vis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some of the correspondences are wrong. So how does our `compute_homography_ransac()` function perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo, mask = compute_homography_ransac(im1_points_orb, im2_points_orb)\n",
    "\n",
    "stitched = warp_images_all([im1, im2], [homo, np.eye(3)])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(stitched)\n",
    "\n",
    "vis = draw_matches(im1, im2, im1_points_orb, im2_points_orb, inlier_mask=mask)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(vis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If implemented correctly, the images should be aligned properly, with the inliers and outliers correctly detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Adding more images\n",
    "You are almost done! Now the last part is to extend the stitching to multiple images. To do so, suppose we have $N$ images $I_1, \\dots, I_N$. We perform pairwise matching between consecutive images (i.e. $I_1 \\to I_2$, $I_2 \\to I_3, \\dots$). We can then set one of the images (e.g. middle one) as the reference image, and warp all the homographies to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function that computes the homography warping matrices for each image from pairwise homography matrices. Specifically, given $\\mathbf{H}_1^2, \\mathbf{H}_2^3, \\dots, \\mathbf{H}_{N-1}^N$ which represents the homography matrices between consecutive images:\n",
    "$$\n",
    "\\mathbf{x}_{k+1} = \\mathbf{H}_{k}^{k+1} \\mathbf{x}_{k},\n",
    "$$\n",
    "compute the absolute homography matrices $\\mathbf{H}_1^{ref}, \\mathbf{H}_2^{ref}, \\dots, \\mathbf{H}_{N-1}^{ref}$ that can be used to warp all images to the reference image:\n",
    "\n",
    "**Implement the following function(s): `concatenate_homographies()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate ORB detector. Detect keypoints and extracts descriptors for all images.\n",
    "orb = cv2.ORB_create()\n",
    "num_images = 4\n",
    "all_im, all_kp, all_des = [], [], []\n",
    "for i in range(num_images):\n",
    "    im = load_image('data/pano_{}.jpg'.format(i))\n",
    "    kp, des = orb.detectAndCompute(cv2.cvtColor(im, cv2.COLOR_BGR2GRAY), None)\n",
    "    all_im.append(im)\n",
    "    all_kp.append(kp)\n",
    "    all_des.append(des)\n",
    "    \n",
    "# Matches the descriptors between consecutive images via brute force matching, and\n",
    "# computes the homography matrices.\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "pairwise_homographies = []\n",
    "for i in range(num_images-1):\n",
    "    matches = bf.match(all_des[i], all_des[i+1])\n",
    "    im1_points_orb, im2_points_orb = matches2pairs(matches, all_kp[i], all_kp[i+1])\n",
    "    h_i1_i, mask = compute_homography_ransac(im1_points_orb, im2_points_orb)\n",
    "    pairwise_homographies.append(h_i1_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_h_matrices = concatenate_homographies(pairwise_homographies, ref=2)\n",
    "\n",
    "stitched = warp_images_all(all_im, all_h_matrices)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(stitched);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented `concatenate_homographies()` correctly, you should get a coherent panorama. Congratulations! You have reached the end of the first assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "title": "CS4277/CS5477 Assignment 1"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
